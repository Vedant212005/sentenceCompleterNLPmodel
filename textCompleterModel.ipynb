{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4rfnWKQxKUOtd8jdcZdXn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBxMApvqbiqE","executionInfo":{"status":"ok","timestamp":1729185073328,"user_tz":-330,"elapsed":8894,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}},"outputId":"0a8c433d-c4bf-4635-b272-25503a573edd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"X2zNYUWM4gk6","executionInfo":{"status":"ok","timestamp":1729185073329,"user_tz":-330,"elapsed":13,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup"]},{"cell_type":"code","source":["URL='https://arxiv.org/list/cs.AI/recent'\n"],"metadata":{"id":"NUDZvjW35J8C","executionInfo":{"status":"ok","timestamp":1729185073329,"user_tz":-330,"elapsed":12,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["response = requests.get(URL)"],"metadata":{"id":"69bHdPOG6PIQ","executionInfo":{"status":"ok","timestamp":1729185073330,"user_tz":-330,"elapsed":13,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["html_content=response.text\n","#html_content"],"metadata":{"id":"s68Lnbf66fdl","executionInfo":{"status":"ok","timestamp":1729185073330,"user_tz":-330,"elapsed":12,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Xkrs0y78_36G","executionInfo":{"status":"ok","timestamp":1729185073330,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["soup = BeautifulSoup(html_content, 'html.parser')\n"],"metadata":{"id":"J4AgG58Y6po9","executionInfo":{"status":"ok","timestamp":1729185074279,"user_tz":-330,"elapsed":960,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["articles_section = soup.find('dl', id='articles')\n"],"metadata":{"id":"lSq5YReA67ql","executionInfo":{"status":"ok","timestamp":1729185074280,"user_tz":-330,"elapsed":29,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Extract PDF links\n","if articles_section:\n","    pdf_links = []\n","    for entry in articles_section.find_all('a', href=True):\n","        if entry['href'].startswith('/pdf/'):\n","            pdf_link = f\"https://arxiv.org{entry['href']}\"  # Construct full link\n","            pdf_links.append(pdf_link)"],"metadata":{"id":"N9hMe838DWes","executionInfo":{"status":"ok","timestamp":1729185074280,"user_tz":-330,"elapsed":28,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["pdf_links"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"De3kKKJ1DfJB","executionInfo":{"status":"ok","timestamp":1729185074280,"user_tz":-330,"elapsed":27,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}},"outputId":"aa08bb30-e6b3-4408-8f03-104cbc68fe36"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['https://arxiv.org/pdf/2410.12784',\n"," 'https://arxiv.org/pdf/2410.12631',\n"," 'https://arxiv.org/pdf/2410.12539',\n"," 'https://arxiv.org/pdf/2410.12509',\n"," 'https://arxiv.org/pdf/2410.12409',\n"," 'https://arxiv.org/pdf/2410.12389',\n"," 'https://arxiv.org/pdf/2410.12376',\n"," 'https://arxiv.org/pdf/2410.12375',\n"," 'https://arxiv.org/pdf/2410.12361',\n"," 'https://arxiv.org/pdf/2410.12288',\n"," 'https://arxiv.org/pdf/2410.12219',\n"," 'https://arxiv.org/pdf/2410.12207',\n"," 'https://arxiv.org/pdf/2410.12126',\n"," 'https://arxiv.org/pdf/2410.12112',\n"," 'https://arxiv.org/pdf/2410.12031',\n"," 'https://arxiv.org/pdf/2410.11905',\n"," 'https://arxiv.org/pdf/2410.11900',\n"," 'https://arxiv.org/pdf/2410.12774',\n"," 'https://arxiv.org/pdf/2410.12773',\n"," 'https://arxiv.org/pdf/2410.12772',\n"," 'https://arxiv.org/pdf/2410.12771',\n"," 'https://arxiv.org/pdf/2410.12761',\n"," 'https://arxiv.org/pdf/2410.12759',\n"," 'https://arxiv.org/pdf/2410.12730',\n"," 'https://arxiv.org/pdf/2410.12728',\n"," 'https://arxiv.org/pdf/2410.12720',\n"," 'https://arxiv.org/pdf/2410.12707',\n"," 'https://arxiv.org/pdf/2410.12705',\n"," 'https://arxiv.org/pdf/2410.12700',\n"," 'https://arxiv.org/pdf/2410.12686',\n"," 'https://arxiv.org/pdf/2410.12683',\n"," 'https://arxiv.org/pdf/2410.12672',\n"," 'https://arxiv.org/pdf/2410.12665',\n"," 'https://arxiv.org/pdf/2410.12662',\n"," 'https://arxiv.org/pdf/2410.12656',\n"," 'https://arxiv.org/pdf/2410.12652',\n"," 'https://arxiv.org/pdf/2410.12641',\n"," 'https://arxiv.org/pdf/2410.12613',\n"," 'https://arxiv.org/pdf/2410.12609',\n"," 'https://arxiv.org/pdf/2410.12607',\n"," 'https://arxiv.org/pdf/2410.12606',\n"," 'https://arxiv.org/pdf/2410.12593',\n"," 'https://arxiv.org/pdf/2410.12591',\n"," 'https://arxiv.org/pdf/2410.12583',\n"," 'https://arxiv.org/pdf/2410.12577',\n"," 'https://arxiv.org/pdf/2410.12568',\n"," 'https://arxiv.org/pdf/2410.12561',\n"," 'https://arxiv.org/pdf/2410.12558',\n"," 'https://arxiv.org/pdf/2410.12543',\n"," 'https://arxiv.org/pdf/2410.12538']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["soup = BeautifulSoup(html_content, 'html.parser')"],"metadata":{"id":"54G7gO8fDmBG","executionInfo":{"status":"ok","timestamp":1729185074280,"user_tz":-330,"elapsed":24,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["papers = []\n","for entry in soup.find_all('div', class_='list-title'):\n","        title = entry.text.strip().replace(\"Title:\", \"\").strip()\n","        #link = entry.find_previous_sibling('div', class_='list-identifier').a['href']\n","        #link = f\"https://arxiv.org{link}.pdf\"  # Direct PDF link\n","        papers.append(title)"],"metadata":{"id":"wmg2ZJ4ZFYd-","executionInfo":{"status":"ok","timestamp":1729185074281,"user_tz":-330,"elapsed":24,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["papers_with_links = list(zip(papers, pdf_links))"],"metadata":{"id":"xt0bSY7WFkwu","executionInfo":{"status":"ok","timestamp":1729185074281,"user_tz":-330,"elapsed":19,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["pdf_paths = []\n"],"metadata":{"id":"P4m17fHZgUvL","executionInfo":{"status":"ok","timestamp":1729185825094,"user_tz":-330,"elapsed":1706,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["for title, pdf_link in papers_with_links:\n","    response = requests.get(pdf_link)\n","\n","    # Save the PDF with the title as the filename\n","    filename = f\"{title}.pdf\"\n","    with open(filename, 'wb') as f:\n","        f.write(response.content)\n","        pdf_paths.append(filename)"],"metadata":{"id":"Cv5UK0xvGGaj","executionInfo":{"status":"ok","timestamp":1729185850466,"user_tz":-330,"elapsed":8299,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["!pip install pdfplumber"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKm2zySMjBRq","executionInfo":{"status":"ok","timestamp":1729185089252,"user_tz":-330,"elapsed":5741,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}},"outputId":"4216496b-8c7c-43f3-9896-176be08a4611"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pdfplumber\n","  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n","  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n","Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n","Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"]}]},{"cell_type":"code","source":["import pdfplumber"],"metadata":{"id":"I42iWDtqbw2a","executionInfo":{"status":"ok","timestamp":1729185089252,"user_tz":-330,"elapsed":42,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["text=\"\""],"metadata":{"id":"z0DqFnM6jbWb","executionInfo":{"status":"ok","timestamp":1729185089252,"user_tz":-330,"elapsed":41,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["for pdf_path in pdf_paths:\n","    with pdfplumber.open(pdf_path) as pdf:\n","        for page in pdf.pages:\n","            text += page.extract_text()"],"metadata":{"id":"T2PkS4ySgLbD","executionInfo":{"status":"ok","timestamp":1729186228207,"user_tz":-330,"elapsed":209691,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["**Till here, our web crawler is prepared, it has scraped the webpage provided, stored the links in a list , downloaded all the pdfs through that download links. Also, now it has extracted the text from the pdfs and storerd it in a list named as text.**"],"metadata":{"id":"wBy4LHNQmMwL"}},{"cell_type":"markdown","source":["Now we will start with text preprocessing, this part involves the cleaning of the dataset, here we will be applying various techniques like lemitization, stemming, stopwords removal, Part of speech tagging and tokenization"],"metadata":{"id":"004OOVAdiYxS"}},{"cell_type":"code","source":["\n","from nltk.stem import WordNetLemmatizer"],"metadata":{"id":"21byhV7fj1OS","executionInfo":{"status":"ok","timestamp":1729192308371,"user_tz":-330,"elapsed":1777,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["lemmatizer=WordNetLemmatizer()"],"metadata":{"id":"LsIyKMxU42jv","executionInfo":{"status":"ok","timestamp":1729192310383,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["from nltk.corpus import stopwords"],"metadata":{"id":"1kyY9zqR5KTl","executionInfo":{"status":"ok","timestamp":1729192363205,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAZNJkna5Wft","executionInfo":{"status":"ok","timestamp":1729192445692,"user_tz":-330,"elapsed":571,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}},"outputId":"706b760e-3451-4d24-bd5b-9c61f7b9993e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["stopword = stopwords.words('english')"],"metadata":{"id":"LVWfIQKQ5fWv","executionInfo":{"status":"ok","timestamp":1729192556102,"user_tz":-330,"elapsed":1731,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["stopword # these are the stopwords which we are going to remove from our dataset to refine it"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ff7uSil6GjV","executionInfo":{"status":"ok","timestamp":1729192795235,"user_tz":-330,"elapsed":878,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}},"outputId":"b48ef59b-895f-4f0c-e2af-939b1ee5ba54"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGGqpgv27NKf","executionInfo":{"status":"ok","timestamp":1729192861855,"user_tz":-330,"elapsed":665,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}},"outputId":"c2340d4f-fa03-46dc-9ee0-5e8d6a222886"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["sentences = nltk.sent_tokenize(text)"],"metadata":{"id":"GX0mau8I6fAT","executionInfo":{"status":"ok","timestamp":1729192865938,"user_tz":-330,"elapsed":1123,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BylqTbBj9WR9","executionInfo":{"status":"ok","timestamp":1729193423802,"user_tz":-330,"elapsed":702,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}},"outputId":"5a1e2e92-1d38-4989-99b2-805469cbf28b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["for i in range (len(sentences)):\n","  words=nltk.word_tokenize(sentences[i])\n","  for j in range (len(words)):\n","    if words[j] not in stopword:\n","      words[j]=lemmatizer.lemmatize(words[j])\n","  sentences[i]=' '.join(words)"],"metadata":{"id":"LxRNK1L47HOU","executionInfo":{"status":"ok","timestamp":1729193435560,"user_tz":-330,"elapsed":9793,"user":{"displayName":"Vedant s","userId":"16952553770473052445"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["Till now our dataset of text is cleaned by removing stopwords and lemmatizing the remaing words. Futher from here i have to encode my texts after which finally i can use it to do fine tuning of GPT or BERT on dataset which i have prepared."],"metadata":{"id":"zCSSfDXJ9k7e"}},{"cell_type":"code","source":[],"metadata":{"id":"d4_q7xxy-eUv"},"execution_count":null,"outputs":[]}]}